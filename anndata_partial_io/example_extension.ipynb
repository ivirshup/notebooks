{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how one would register extensions to the `h5ad` file format via `anndata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import h5py\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_partial_registry import read, write, _REGISTRY, IOSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.settings.datasetdir = \"/Users/isaac/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing arbitrary objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Foo(object):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "\n",
    "@_REGISTRY.register_write(Foo, IOSpec(\"Foo\", \"0.1.0\"))\n",
    "def write_foo(g, k, v, dataset_kwargs={}):\n",
    "    if \"compression\" in dataset_kwargs:\n",
    "        dataset_kwargs = dict(dataset_kwargs)\n",
    "        dataset_kwargs.pop(\"compression\")\n",
    "    g.create_dataset(k, data=np.void(pickle.dumps(v)), **dataset_kwargs)\n",
    "\n",
    "\n",
    "@_REGISTRY.register_read(IOSpec(\"Foo\", \"0.1.0\"))\n",
    "def read_foo(v):\n",
    "    return pickle.loads(v[...].tobytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbmc = sc.datasets.pbmc3k_processed()\n",
    "pbmc.uns[\"foo\"] = Foo({\"a\": {\"b\": 1}}, \"lorem ipsum\")\n",
    "\n",
    "write(pbmc, \"out.h5ad\", dataset_kwargs={\"compression\": \"lzf\"})\n",
    "from_disk = read(\"out.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The element is just a normal element on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "draw_graph               Group\n",
      "foo                      Dataset {SCALAR}\n",
      "louvain                  Group\n",
      "louvain_colors           Dataset {8}\n",
      "neighbors                Group\n",
      "pca                      Group\n",
      "rank_genes_groups        Group\n"
     ]
    }
   ],
   "source": [
    "!h5ls out.h5ad/uns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep the information neccesary for reading and writing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoding-type': 'Foo', 'encoding-version': '0.1.0'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with h5py.File(\"out.h5ad\", \"r\") as f:\n",
    "    display(dict(f[\"uns/foo\"].attrs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas extension arrays\n",
    "\n",
    "This example is mostly to show what's possible, not exactly what should be done. I'm not sure we want to support the sparse array type directly in anndata, since reading it in an at all efficient way requires private pandas functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_partial_registry import write_elem, read_elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.array.SparseArray\n",
    "@_REGISTRY.register_write(pd.arrays.SparseArray, IOSpec(\"pd-sparse-array\", \"0.1.0\"))\n",
    "def write_pandas_sparse(f, k, v, dataset_kwargs={}):\n",
    "    g = f.create_group(k)\n",
    "    write_elem(g, \"fill-value\", v.fill_value, dataset_kwargs=dataset_kwargs)\n",
    "    write_elem(g, \"sparse-index\", v.sp_index, dataset_kwargs=dataset_kwargs)\n",
    "    write_elem(g, \"sparse-values\", v.sp_values, dataset_kwargs=dataset_kwargs)\n",
    "\n",
    "\n",
    "@_REGISTRY.register_read(IOSpec(\"pd-sparse-array\", \"0.1.0\"))\n",
    "def read_pandas_sparse(g):\n",
    "    return pd.arrays.SparseArray(\n",
    "        read_elem(g[\"sparse-values\"]),\n",
    "        sparse_index=read_elem(g[\"sparse-index\"]),\n",
    "        fill_value=read_elem(g[\"fill-value\"]),\n",
    "    )\n",
    "\n",
    "\n",
    "@_REGISTRY.register_write(pd._libs.sparse.IntIndex, IOSpec(\"pd-sparse-int-index\", \"0.1.0\"))\n",
    "def write_pandas_sparse_int_index(f, k, v, dataset_kwargs):\n",
    "    d = f.create_dataset(k, data=v.indices, **dataset_kwargs)\n",
    "    d.attrs[\"length\"] = v.length\n",
    "\n",
    "@_REGISTRY.register_read(IOSpec(\"pd-sparse-int-index\", \"0.1.0\"))\n",
    "def read_pandas_sparse_int_index(g):\n",
    "    return pd._libs.sparse.IntIndex(g.attrs[\"length\"], g[...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test writing an individual element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = pd.arrays.SparseArray.from_spmatrix(sparse.random(100, 1, density=0.5))\n",
    "\n",
    "with h5py.File(\"test.h5\", \"w\") as f:\n",
    "    write_elem(f, \"pd-sparse\", sa)\n",
    "    sa_from_disk = read_elem(f[\"pd-sparse\"])\n",
    "\n",
    "pd.testing.assert_extension_array_equal(sa, sa_from_disk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing a dataframe with sparse columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbmc.obs[\"b-cell\"] = pd.arrays.SparseArray(pbmc.obs[\"louvain\"] == \"B cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "write(pbmc, \"out.h5ad\")\n",
    "from_disk = read(\"out.h5ad\")\n",
    "\n",
    "pd.testing.assert_series_equal(pbmc.obs[\"b-cell\"], from_disk.obs[\"b-cell\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
